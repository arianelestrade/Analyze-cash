{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alive-father",
   "metadata": {},
   "source": [
    "# Extraits de tweets pour les traducteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atomic-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import re \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils import query_to_words\n",
    "from utils import score_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "religious-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advanced-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df, query, sort_by_relevance=True): \n",
    "    df = df.copy()\n",
    "    # Substitute [URL_LINK] for HTTP(S) pattern, clean HTML code.\n",
    "    df[\"clean_tweet\"] =  df.tweet.str.replace(r'http\\S+', '[URL_LINK]') # \\S : Matches any character which is not a whitespace character. This is the opposite of \\s. If the ASCII flag is used this becomes the equivalent of [^ \\t\\n\\r\\f\\v].\n",
    "    for html_code, replace_string in HTML_CODE:\n",
    "        df[\"clean_tweet\"] = df[\"clean_tweet\"].str.replace(html_code, replace_string, regex=False)\n",
    "    df = df.drop_duplicates(subset=\"clean_tweet\")\n",
    "        \n",
    "    # Calcule score de pertinence des tweets : plus le score est élevé, plus le tweet est pertinent. \n",
    "    words = query_to_words(query)\n",
    "    df[\"relevance_score\"] = df.clean_tweet.str.count(pat=\"|\".join(words))\n",
    "    \n",
    "    # Sorting if necessary\n",
    "    if sort_by_relevance:\n",
    "        df.sort_values(\"relevance_score\", inplace=True, ascending=False)\n",
    "    \n",
    "    return df[[\"created_at\", \"username\", \"name\", \"clean_tweet\", \"relevance_score\", \"tweet\"]]\n",
    "  \n",
    "def generate_output_for_trad(df, n_sample=100): \n",
    "    out = pd.DataFrame({\n",
    "        \"Non conforme\": None,\n",
    "        \"Mots-clés relevés (si non conforme)\": None, \n",
    "        \"Remarques\": None,\n",
    "        \"Tweet\": df.clean_tweet.sample(n_sample).tolist(), \n",
    "    })\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-dominican",
   "metadata": {},
   "source": [
    "### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occupational-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_CODE = [\n",
    "    (r'&gt;', '>'),\n",
    "    (r'&lt;', '<'),\n",
    "    (r'&amp;', '&'),\n",
    "]\n",
    "\n",
    "QUERY_DATA_PATH = \"/home/cash/data/queries\"\n",
    "OUTPUT_TRAD_PATH = \"/home/cash/output/traduction\"\n",
    "\n",
    "CSV_KWARGS = {\n",
    "    \"sep\": \";\",\n",
    "    \"encoding\": \"UTF-8\",\n",
    "    \"index\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compound-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_TRAD_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-drilling",
   "metadata": {},
   "source": [
    "### SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noted-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "QUERY_ENGLISH = '(cash OR banknotes OR banknote OR \" note \" OR \" coin \" OR \" coins \" OR money OR currency OR withdrawals OR withdrawal OR ATM OR ATMs OR cash machines OR branch OR counter OR card OR cards OR \"contactless\" OR \" visa \" OR mastercard OR \"cash back\" OR \" NFC \" OR \"Google Pay\" OR \"ApplePay\" OR \"Paylib\" OR \"Lydia\" OR \"Lyf Pay\" OR \"Alipay\" OR \"Samsung Pay\" OR \"Stocard Pay\" OR \"mobile payments\" OR \"cheques\") AND (payment OR payments OR \" pay \" OR \" pays \" OR settle OR \" buy \" OR \" buys \" OR purchases OR purchase OR withdraw OR spend OR expenses OR spending OR expenditure)'\n",
    "path_cash_en = join(QUERY_DATA_PATH, \"query_en_cash.csv\")\n",
    "path_cb_en = join(QUERY_DATA_PATH, \"query_en_cb.csv\")\n",
    "\n",
    "# Spanish\n",
    "QUERY_SP = '(efectivo OR metálico OR billetes OR billete OR moneda OR monedas OR dinero OR efectivo OR líquido OR retiradas OR retirada OR cajero OR cajeros OR \" cajero automático \" OR \" caja \" OR \" cajas \" OR efectivo OR metálico OR billetes OR billete OR moneda OR monedas OR dinero OR efectivo OR líquido OR retiradas OR retirada OR cajero OR cajeros OR \" cajero automático \" OR \" caja \" OR \" cajas \") AND (\" pago \" OR pagos OR pagar OR abonos OR abono OR abonar OR compra OR compras OR comprar OR retirar OR gastar OR gasto OR gastos)'\n",
    "path_cash_sp = join(QUERY_DATA_PATH, \"query_sp_cash_part1.csv\")\n",
    "path_cb_sp = join(QUERY_DATA_PATH, \"query_sp_cb.csv\")\n",
    "\n",
    "# German\n",
    "QUERY_GE = '(bargeld OR banknoten OR banknote OR münze OR münzen OR kleingeld OR \" bar \" OR abhebungen OR abhebung OR geldautomat OR geldautomaten OR \" GAA \" OR schalter OR karte OR karten OR \" CB \" OR kontaktlos OR visa OR mastercard OR cashback OR \" NFC \" OR \"Google Pay\" OR ApplePay OR Paylib OR Lydia OR \"Lyf Pay\" OR  Alipay OR \"Samsung Pay\" OR \"Stocard Pay\" OR \"mobiles bezahlen\" OR schecks) AND (zahlung OR zahlungen OR zahlen OR bezahlungen OR bezahlung OR bezahlen OR kauf OR käufe OR kaufen OR abheben OR ausgeben OR ausgabe OR ausgaben)'\n",
    "path_cash_ge = join(QUERY_DATA_PATH, \"query_ge_cash.csv\")\n",
    "path_cb_ge = join(QUERY_DATA_PATH, \"query_ge_cb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-bride",
   "metadata": {},
   "source": [
    "### English query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ambient-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output cash \n",
    "df_cash_en = pd.read_csv(path_cash_en)\n",
    "df_cash_en = format_df(df_cash_en, QUERY_ENGLISH)\n",
    "v1_en_cash_output_for_trad = generate_output_for_trad(df_cash_en)\n",
    "v1_en_cash_output_for_trad.to_csv(join(OUTPUT_TRAD_PATH, \"v1_en_cash_output_for_trad.csv\"), **CSV_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "still-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output cb\n",
    "df_cb_en = pd.read_csv(path_cb_en, nrows=10_000)\n",
    "df_cb_en = format_df(df_cb_en, QUERY_ENGLISH)\n",
    "v1_en_cb_output_for_trad = generate_output_for_trad(df_cb_en)\n",
    "v1_en_cb_output_for_trad.to_csv(join(OUTPUT_TRAD_PATH, \"v1_en_cb_output_for_trad.csv\"), **CSV_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-meaning",
   "metadata": {},
   "source": [
    "### Spanish query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interesting-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output cash \n",
    "df_cash_sp = pd.read_csv(path_cash_sp)\n",
    "df_cash_sp = format_df(df_cash_sp, QUERY_SP)\n",
    "v1_sp_cash_output_for_trad = generate_output_for_trad(df_cash_sp)\n",
    "v1_sp_cash_output_for_trad.to_csv(join(OUTPUT_TRAD_PATH, \"v1_sp_cash_output_for_trad.csv\"), **CSV_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boring-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output cb\n",
    "df_cb_sp = pd.read_csv(path_cb_sp)\n",
    "df_cb_sp = format_df(df_cb_sp, QUERY_SP)\n",
    "v1_sp_cb_output_for_trad = generate_output_for_trad(df_cb_sp)\n",
    "v1_sp_cb_output_for_trad.to_csv(join(OUTPUT_TRAD_PATH, \"v1_sp_cb_output_for_trad.csv\"), **CSV_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-anatomy",
   "metadata": {},
   "source": [
    "### German query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "former-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output cash \n",
    "df_cash_ge = pd.read_csv(path_cash_ge)\n",
    "df_cash_ge = format_df(df_cash_ge, QUERY_GE)\n",
    "v1_ge_cash_output_for_trad = generate_output_for_trad(df_cash_ge)\n",
    "v1_ge_cash_output_for_trad.to_csv(join(OUTPUT_TRAD_PATH, \"v1_ge_cash_output_for_trad.csv\"), **CSV_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "covered-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output cb\n",
    "df_cb_ge = pd.read_csv(path_cb_ge)\n",
    "df_cb_ge = format_df(df_cb_ge, QUERY_GE)\n",
    "v1_ge_cb_output_for_trad = generate_output_for_trad(df_cb_ge)\n",
    "v1_ge_cb_output_for_trad.to_csv(join(OUTPUT_TRAD_PATH, \"v1_ge_cb_output_for_trad.csv\"), **CSV_KWARGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
